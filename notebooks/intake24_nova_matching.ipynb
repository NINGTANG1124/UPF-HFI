{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/DkhmJGBxLCTHWNCLkyFu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NINGTANG1124/UPF-HFI/blob/main/notebooks/intake24_nova_matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connect googledrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v9izKK0g9LUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: è¯»å– intake æ•°æ®ï¼ˆå« Descriptionen å’Œ FoodGroupenï¼‰\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/UPF-HFI/Bradford_original data/1. Dietmasterfile_foodlevel_clean.xls\"\n",
        "intake_df = pd.read_excel(file_path)\n"
      ],
      "metadata": {
        "id": "c7bYEbA49bs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: æ¸…æ´— Descriptionen åˆ—\n",
        "def clean_description(desc):\n",
        "    if pd.isna(desc):\n",
        "        return \"\"\n",
        "    desc = str(desc).lower()\n",
        "    desc = re.sub(r\"[()\\.,\\-]\", \"\", desc)\n",
        "    desc = re.sub(r\"\\s+\", \" \", desc)\n",
        "    return desc.strip()\n",
        "\n",
        "intake_df[\"food_name_clean\"] = intake_df[\"Descriptionen\"].apply(clean_description)\n",
        "intake_df[\"Foodgroupen\"] = intake_df[\"Foodgroupen\"].fillna(\"\")\n"
      ],
      "metadata": {
        "id": "QbNxG8Re9glK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: å®šä¹‰æè¿°å­—æ®µçš„è§„åˆ™åŒ¹é…å‡½æ•°ï¼ˆå®è§‚â†’å¾®è§‚ï¼‰\n",
        "def match_nova_by_description_v3(text):\n",
        "    text = str(text).lower()\n",
        "\n",
        "    # === NOVA 1: å®è§‚ raw / water ===\n",
        "    if \"raw\" in text:\n",
        "        return 1, \"raw\"\n",
        "    if any(word in text for word in [\"tap water\", \"still water\", \"filtered water\"]):\n",
        "        return 1, \"water\"\n",
        "\n",
        "    # === NOVA 3: å®è§‚ homemade / boiled ===\n",
        "    if \"homemade\" in text or \"home made\" in text:\n",
        "        return 3, \"homemade item\"\n",
        "    if \"boiled\" in text or \"mashed potato\" in text:\n",
        "        return 3, \"boiled or mashed\"\n",
        "    if \"porridge made with milk\" in text:\n",
        "        return 3, \"porridge w/ milk\"\n",
        "\n",
        "    # === NOVA 4: å®è§‚åŠ å·¥ç±» ===\n",
        "    if \"takeaway\" in text:\n",
        "        return 4, \"fast food\"\n",
        "    if any(word in text for word in [\"ice cream topping\", \"breakfast cereal\", \"milkshake\"]):\n",
        "        return 4, \"dessert/snack item\"\n",
        "    if any(word in text for word in [\"flavour\", \"instant\"]):\n",
        "        return 4, \"instant/flavoured\"\n",
        "    if any(word in text for word in [\"cracker\", \"biscuit\", \"weetabix\"]):\n",
        "        return 4, \"snack item\"\n",
        "    if \"ketchup\" in text and \"home made\" not in text:\n",
        "        return 4, \"processed ketchup\"\n",
        "    if any(word in text for word in [\"squash\", \"cordial\", \"carbonated\"]):\n",
        "        return 4, \"sweetened drink\"\n",
        "    if any(word in text for word in [\"margarine\", \"clover spread\", \"flora\"]):\n",
        "        return 4, \"processed fat\"\n",
        "    if \"nutella\" in text:\n",
        "        return 4, \"branded sweet spread\"\n",
        "\n",
        "    # === NOVA 1: å¾®è§‚ä¹³åˆ¶å“ç±» ===\n",
        "    if any(word in text for word in [\"natural yoghurt\", \"whole milk\", \"fromage frais\"]) and \"flavour\" not in text:\n",
        "        return 1, \"plain dairy\"\n",
        "\n",
        "    return None, None\n"
      ],
      "metadata": {
        "id": "U_Q2G3Ez93zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: å®šä¹‰ group å­—æ®µçš„åŒ¹é…å‡½æ•°ï¼ˆå®è§‚â†’å¾®è§‚ï¼‰\n",
        "def match_nova_by_group_v2(group):\n",
        "    group = str(group).lower().strip()\n",
        "\n",
        "    # === NOVA 1 ===\n",
        "    if \"fresh fruit\" in group:\n",
        "        return 1, \"fruit (group)\"\n",
        "    if \"dried fruit\" in group:\n",
        "        return 1, \"dried fruit (group)\"\n",
        "    if \"vegetables\" in group and \"fried\" not in group:\n",
        "        return 1, \"vegetables (group)\"\n",
        "\n",
        "    # === NOVA 3 ===\n",
        "    if \"monounsaturated\" in group:\n",
        "        return 3, \"culinary fat (mono)\"\n",
        "    if \"dairy fat spreads\" in group or \"hard marg\" in group:\n",
        "        return 3, \"dairy fat spread\"\n",
        "\n",
        "    # === NOVA 4 ===\n",
        "    if \"other breakfast cereals\" in group or \"muesli\" in group or \"bran flakes\" in group:\n",
        "        return 4, \"processed cereal (group)\"\n",
        "    if \"ice cream\" in group or \"desserts and lollies\" in group:\n",
        "        return 4, \"ice cream (group)\"\n",
        "    if any(word in group for word in [\"sweets\", \"toffee\", \"boiled sweets\", \"gums\", \"jellies\", \"mints\", \"liquorice\", \"raw jelly\", \"popcorn\"]):\n",
        "        return 4, \"sweets/snack (group)\"\n",
        "\n",
        "    return None, None"
      ],
      "metadata": {
        "id": "7apLqZ-_-ECr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: åº”ç”¨åŒ¹é…é€»è¾‘ï¼ˆä¼˜å…ˆ descriptionï¼Œå†è¡¥ groupï¼‰\n",
        "intake_df[[\"NOVA_by_desc\", \"Match_reason\"]] = intake_df[\"Descriptionen\"].apply(\n",
        "    lambda x: pd.Series(match_nova_by_description_v3(x))\n",
        ")\n",
        "\n",
        "mask_unmatched = intake_df[\"NOVA_by_desc\"].isna()\n",
        "intake_df.loc[mask_unmatched, [\"NOVA_by_desc\", \"Match_reason\"]] = intake_df.loc[mask_unmatched, \"Foodgroupen\"].apply(\n",
        "    lambda x: pd.Series(match_nova_by_group_v2(x))\n",
        ")\n",
        "\n",
        "# Step 6: å±•ç¤ºåŒ¹é…æ ·æœ¬ç»“æœ\n",
        "matched_sample = intake_df[[\"food_name_clean\", \"Foodgroupen\", \"NOVA_by_desc\", \"Match_reason\"]].query(\"NOVA_by_desc.notna()\").head(20)\n",
        "matched_sample"
      ],
      "metadata": {
        "id": "_L-ZR4W9-LxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intake_df[\"NOVA_step1\"] = intake_df[\"NOVA_by_desc\"]\n"
      ],
      "metadata": {
        "id": "nzZB2lkh3_es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_save = [\n",
        "    \"food_name_clean\", \"Descriptionen\", \"Foodgroupen\",\n",
        "    \"NOVA_step1\", \"Match_reason\"\n",
        "]\n",
        "\n",
        "intake_df[cols_to_save].to_excel(\"/content/drive/MyDrive/UPF-HFI/outcome/intake_with_nova_step1.xlsx\", index=False)\n"
      ],
      "metadata": {
        "id": "Q9bpa0kH4CNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intake_df[cols_to_save].to_csv(\"/content/drive/MyDrive/UPF-HFI/outcome/intake_with_nova_step1.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "zNpLXy-_4YZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ”¹ Step 2: TF-IDF é«˜é˜ˆå€¼åŒ¹é…ï¼ˆ>0.99ï¼‰ã€æ•°æ®æºï¼šVKesaiteã€‘ Intake æè¿° vs FoodName å­—æ®µ ç‰¹ç‚¹ï¼šè‹±å›½ NDNS æ•°æ®ï¼Œè¯­ä¹‰è´´åˆåº¦é«˜ åŒ¹é…åå­—æ®µï¼š Matched_NOVA Source = 'tfidf_vk_099' Similarity_score\n",
        "\n",
        "ğŸ”¹ Step 3: TF-IDF ä¸­é˜ˆå€¼åŒ¹é…ï¼ˆ>0.85ï¼‰ã€æ•°æ®æºï¼šGiulia FNDDSã€‘ Intake æè¿° vs FoodName/Description å­—æ®µï¼ˆè§†ç»“æ„è€Œå®šï¼‰ ç‰¹ç‚¹ï¼šåŒ¹é…é¢å¹¿ä½†é£æ ¼åç¾å¼ å¯ä½œä¸ºç¬¬äºŒæƒé‡åŒ¹é…æºè¡¥å……ç©ºå€¼ åŒ¹é…åï¼š Source = 'tfidf_giulia_085'\n",
        "\n",
        "ğŸ”¹ Step 4: TF-IDF æˆ– SBERT è¯­ä¹‰åŒ¹é…ï¼ˆ>0.85ï¼‰ã€æ•°æ®æºï¼šOFFã€‘ ä¸¤ç§æ–¹å¼éƒ½å¯ç”¨ï¼š TF-IDF åŒ¹é… product_name å­—æ®µ SBERT åŒ¹é…æè¿°ï¼ˆæ¨è MiniLM ï¼‰ ç”¨äºæœ€åè¡¥å……ç©ºå€¼ï¼Œæé«˜ recallï¼ˆå¬å›ç‡ï¼‰ åŒ¹é…åï¼š Source = 'tfidf_off' æˆ– 'sbert_off'\n",
        "\n",
        "ğŸ”¹ Step 5: æ•´åˆ + äººå·¥è¡¥å…¨ + Final è¾“å‡º"
      ],
      "metadata": {
        "id": "2TluyxWVNvxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# novaæ–‡ä»¶æ•°æ®æ¸…æ´—\n",
        "# ndns\n",
        "ndns_df = pd.read_csv(\"/content/drive/MyDrive/UPF-HFI/nova/NDNS_NOVA_DATABASE.new2023.csv\", encoding=\"ISO-8859-1\")\n",
        "ndns_df.columns = ndns_df.columns.str.strip()\n",
        "ndns_df = ndns_df[[\"FoodName\", \"NOVA\"]].dropna()\n",
        "ndns_df[\"FoodName_clean\"] = ndns_df[\"FoodName\"].str.lower().str.replace(r\"[^\\w\\s]\", \" \", regex=True).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
        "ndns_df = ndns_df.drop_duplicates(subset=[\"FoodName_clean\"])\n"
      ],
      "metadata": {
        "id": "OMkARVTN1cMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "giulia_df = pd.read_excel(\"/content/drive/MyDrive/UPF-HFI/nova/Training Data Original Given by NOVA Researchers - Corrections by Giulia Babak FNDDS 2009-10.xls\")\n",
        "giulia_df.columns = giulia_df.columns.str.strip()\n",
        "print(giulia_df.columns.tolist())  # æ‰¾å‡ºæ­£ç¡®åˆ—å\n"
      ],
      "metadata": {
        "id": "eJyrI0Mx2Zvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ç¾å›½çš„\n",
        "giulia_df = pd.read_excel(\"/content/drive/MyDrive/UPF-HFI/nova/Training Data Original Given by NOVA Researchers - Corrections by Giulia Babak FNDDS 2009-10.xls\")\n",
        "giulia_df.columns = giulia_df.columns.str.strip()\n",
        "\n",
        "giulia_df = giulia_df[[\"Main_food_description\", \"SR_nova_group\"]].dropna()\n",
        "giulia_df = giulia_df.rename(columns={\"Main_food_description\": \"FoodName\", \"SR_nova_group\": \"NOVA\"})\n",
        "\n",
        "giulia_df[\"FoodName_clean\"] = giulia_df[\"FoodName\"].str.lower().str.replace(r\"[^\\w\\s]\", \" \", regex=True).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
        "giulia_df = giulia_df.drop_duplicates(subset=[\"FoodName_clean\"])\n"
      ],
      "metadata": {
        "id": "AgvkK3io1vib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# offçš„\n",
        "off_clean = []\n",
        "with open(\"/content/drive/MyDrive/UPF-HFI/nova/openfoodfacts-popular-24.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            entry = json.loads(line)\n",
        "            if not isinstance(entry, dict):\n",
        "                continue  # è·³è¿‡éå¯¹è±¡\n",
        "            name = entry.get(\"product_name\") or entry.get(\"abbreviated_product_name\")\n",
        "            nova = entry.get(\"nova_group\")\n",
        "            if name and nova:\n",
        "                name_clean = re.sub(r\"[^\\w\\s]\", \" \", name.lower())\n",
        "                name_clean = re.sub(r\"\\s+\", \" \", name_clean).strip()\n",
        "                off_clean.append({\"FoodName_clean\": name_clean, \"NOVA\": nova})\n",
        "        except json.JSONDecodeError:\n",
        "            continue  # å¿½ç•¥é”™è¯¯è¡Œ\n",
        "\n",
        "off_df = pd.DataFrame(off_clean).drop_duplicates(subset=[\"FoodName_clean\"])\n"
      ],
      "metadata": {
        "id": "rjtOfuR12Idz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ndns_df.to_csv(\"NDNS_clean.csv\", index=False)\n",
        "giulia_df.to_csv(\"Giulia_clean.csv\", index=False)\n",
        "off_df.to_csv(\"OFF_clean.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "4xz6rJST2_lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Step 2ï¼šTF-IDF åŒ¹é…æœªå®Œæˆéƒ¨åˆ†ï¼ˆåŸºäº NOVA å¯¹ç…§æ± ï¼‰\n",
        "\n",
        "# ğŸ§± 1. åˆå¹¶å¯¹ç…§åº“ä½œä¸º TF-IDF çš„ reference\n",
        "nova_pool = pd.concat([ndns_df, giulia_df, off_df], ignore_index=True)\n",
        "nova_pool = nova_pool.drop_duplicates(subset=[\"FoodName_clean\"])\n",
        "\n",
        "# ğŸ§± 2. åŠ è½½ intake åŸå§‹æ•°æ®ï¼ˆå« Step1 ç»“æœï¼‰\n",
        "intake_df = pd.read_csv(\"/content/drive/MyDrive/UPF-HFI/outcome/intake_with_nova_step1.csv\")\n",
        "\n",
        "# ğŸ§± 3. é€‰å‡º NOVA_step1 æ˜¯ç¼ºå¤±çš„é£Ÿç‰©\n",
        "mask_missing = intake_df[\"NOVA_step1\"].isna()\n",
        "query_texts = intake_df.loc[mask_missing, \"food_name_clean\"].dropna()\n",
        "query_texts_index = query_texts.index\n",
        "\n",
        "# ğŸ§± 4. æ„å»º TF-IDF å‘é‡å™¨å¹¶è½¬æ¢\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_ref = vectorizer.fit_transform(nova_pool[\"FoodName_clean\"])\n",
        "tfidf_query = vectorizer.transform(query_texts)\n",
        "\n",
        "# ğŸ§± 5. åŒ¹é…å¹¶è¿”å›å¾—åˆ†å’ŒåŒ¹é…å†…å®¹\n",
        "similarity_matrix = cosine_similarity(tfidf_query, tfidf_ref)\n",
        "best_match_idx = similarity_matrix.argmax(axis=1)\n",
        "best_match_score = similarity_matrix.max(axis=1)\n",
        "matched_nova = nova_pool.iloc[best_match_idx][\"NOVA\"].values\n",
        "matched_name = nova_pool.iloc[best_match_idx][\"FoodName_clean\"].values\n",
        "\n",
        "# ğŸ§± 6. å›å†™ intake_df ä¸­\n",
        "intake_df.loc[query_texts_index, \"NOVA_step2\"] = matched_nova\n",
        "intake_df.loc[query_texts_index, \"TFIDF_score\"] = best_match_score\n",
        "intake_df.loc[query_texts_index, \"TFIDF_match_name\"] = matched_name\n",
        "\n",
        "# âœ… å¯é€‰ï¼šè®¾ç½®åŒ¹é…é˜ˆå€¼\n",
        "threshold = 0.85\n",
        "intake_df.loc[intake_df[\"TFIDF_score\"] < threshold, [\"NOVA_step2\", \"TFIDF_match_name\"]] = [None, None]\n",
        "\n",
        "# âœ… ä¿å­˜è¾“å‡º\n",
        "intake_df.to_csv(\"/content/drive/MyDrive/UPF-HFI/outcome/intake_with_nova_step2.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "X-NxAZia6Jl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Step 2 åˆ†æä»£ç \n",
        "# âœ… 1. åŒ¹é…æˆåŠŸæ•°é‡å’Œæ¯”ä¾‹\n",
        "matched_tfidf = intake_df[\"NOVA_step2\"].notna().sum()\n",
        "total_tfidf_targets = intake_df[\"NOVA_step1\"].isna().sum()\n",
        "match_rate_tfidf = matched_tfidf / total_tfidf_targets\n",
        "\n",
        "print(f\"ğŸ” Step 2ï¼ˆTF-IDFï¼‰åŒ¹é…æˆåŠŸæ•°: {matched_tfidf} / {total_tfidf_targets} = {match_rate_tfidf:.2%}\")\n",
        "\n",
        "# âœ… 2. åŒ¹é…ç½®ä¿¡åº¦ç»Ÿè®¡\n",
        "print(\"\\nğŸ“Š TF-IDF åŒ¹é…å¾—åˆ†æè¿°æ€§ç»Ÿè®¡ï¼š\")\n",
        "print(intake_df[\"TFIDF_score\"].describe())\n",
        "\n",
        "# âœ… 3. æŸ¥çœ‹ä½ç½®ä¿¡åº¦ï¼ˆå¾—åˆ† < 0.85ï¼‰ç¤ºä¾‹\n",
        "low_confidence = intake_df.query(\"TFIDF_score < 0.85 and TFIDF_score.notna()\").sort_values(by=\"TFIDF_score\")\n",
        "low_confidence[[\"food_name_clean\", \"TFIDF_match_name\", \"TFIDF_score\", \"NOVA_step2\"]].head(10)\n"
      ],
      "metadata": {
        "id": "IFYnCDwA61cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ§© Step 3ï¼šåˆå¹¶ Step1 ä¸ Step2 åŒ¹é…ç»“æœï¼Œå½¢æˆæœ€ç»ˆ NOVA åˆ—\n",
        "\n",
        "def combine_nova(row):\n",
        "    if pd.notna(row[\"NOVA_step1\"]):\n",
        "        return row[\"NOVA_step1\"]\n",
        "    elif pd.notna(row[\"NOVA_step2\"]):\n",
        "        return row[\"NOVA_step2\"]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "intake_df[\"NOVA_final\"] = intake_df.apply(combine_nova, axis=1)\n",
        "\n",
        "# åŒæ—¶ä¿ç•™æ¥æºï¼ˆè¯´æ˜åŒ¹é…æ¥æºæ˜¯ Step1 / Step2 / Noneï¼‰\n",
        "def get_reason(row):\n",
        "    if pd.notna(row[\"NOVA_step1\"]):\n",
        "        return \"Keyword\"\n",
        "    elif pd.notna(row[\"NOVA_step2\"]):\n",
        "        return \"TF-IDF\"\n",
        "    else:\n",
        "        return \"Unmatched\"\n",
        "\n",
        "intake_df[\"Match_source\"] = intake_df.apply(get_reason, axis=1)\n",
        "\n",
        "# âœ… ä¿å­˜æœ€ç»ˆç»“æœ\n",
        "intake_df.to_csv(\"/content/drive/MyDrive/UPF-HFI/outcome/intake_with_nova_step3.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "NX-zuEsc6jRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Step 3 åˆ†æä»£ç ï¼š\n",
        "# âœ… 1. åŒ¹é…æ¥æºåˆ†å¸ƒ\n",
        "print(\"\\nğŸ“Š åŒ¹é…æ¥æºåˆ†å¸ƒç»Ÿè®¡ï¼š\")\n",
        "print(intake_df[\"Match_source\"].value_counts(dropna=False))\n",
        "print(\"\\nğŸ“Š åŒ¹é…æ¥æºç™¾åˆ†æ¯”ï¼š\")\n",
        "print(intake_df[\"Match_source\"].value_counts(normalize=True, dropna=False).map(\"{:.2%}\".format))\n",
        "\n",
        "# âœ… 2. å¯é€‰ï¼šæ¯ç§ Match_source åœ¨ Foodgroupen ä¸­çš„åˆ†å¸ƒï¼ˆå¦‚éœ€æ·±å…¥åˆ†æï¼‰\n",
        "# pd.crosstab(intake_df[\"Foodgroupen\"], intake_df[\"Match_source\"])\n"
      ],
      "metadata": {
        "id": "ieBV0-RY6-Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ¯ Step 4ï¼šä½¿ç”¨ SBERT å¯¹å‰©ä½™ NOVA_final ä¸ºç©ºçš„é£Ÿç‰©è¿›è¡Œè¯­ä¹‰åŒ¹é…è¡¥å…¨"
      ],
      "metadata": {
        "id": "bcR92-jE7KdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "PqbMD6e87JlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆæ¨è all-MiniLM-L6-v2ï¼‰ï¼š\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
      ],
      "metadata": {
        "id": "x-po5i9d7vel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ›  Step 4ï¼šå¯¹ NOVA_final ä¸ºç©ºçš„é£Ÿç‰©è¿›è¡Œ SBERT åŒ¹é…\n",
        "# âœ… 1. å‡†å¤‡å€™é€‰åº“ï¼ˆå¯¹ nova_pool ç¼–ç ï¼‰\n",
        "# ç¡®ä¿ä½ ä¹‹å‰å‡†å¤‡å¥½çš„ nova_pool æœ‰ FoodName_clean åˆ—\n",
        "ref_texts = nova_pool[\"FoodName_clean\"].tolist()\n",
        "ref_embeddings = model.encode(ref_texts, convert_to_tensor=True)\n"
      ],
      "metadata": {
        "id": "LCxkp7aG71gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 2. é€‰å–å¾…åŒ¹é…é£Ÿç‰©ï¼ˆNOVA_final ä¸ºç©ºï¼‰\n",
        "unmatched_df = intake_df[intake_df[\"NOVA_final\"].isna()].copy()\n",
        "query_texts = unmatched_df[\"food_name_clean\"].dropna().tolist()\n",
        "query_indices = unmatched_df[\"food_name_clean\"].dropna().index\n",
        "\n",
        "query_embeddings = model.encode(query_texts, convert_to_tensor=True)\n"
      ],
      "metadata": {
        "id": "lrebQJ1R75Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 3. è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦å¹¶æå–åŒ¹é…ç»“æœ\n",
        "cosine_scores = util.pytorch_cos_sim(query_embeddings, ref_embeddings)\n",
        "top_scores, top_indices = torch.max(cosine_scores, dim=1)\n",
        "\n",
        "# å†™å…¥ç»“æœ\n",
        "intake_df.loc[query_indices, \"SBERT_score\"] = top_scores.cpu().numpy()\n",
        "intake_df.loc[query_indices, \"SBERT_match_name\"] = nova_pool.iloc[top_indices.cpu().numpy()][\"FoodName_clean\"].values\n",
        "intake_df.loc[query_indices, \"NOVA_step4\"] = nova_pool.iloc[top_indices.cpu().numpy()][\"NOVA\"].values\n"
      ],
      "metadata": {
        "id": "C6GsX7UD79Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 4. æ›´æ–°æœ€ç»ˆåˆ—ï¼šNOVA_final + Match_source\n",
        "# å¦‚æœ Step3 æ²¡æ‰¾åˆ°ä½† Step4 æ‰¾åˆ°äº†ï¼Œä½¿ç”¨ SBERT åŒ¹é…ç»“æœ\n",
        "intake_df[\"NOVA_final\"] = intake_df[\"NOVA_final\"].combine_first(intake_df[\"NOVA_step4\"])\n",
        "\n",
        "# åŒæ ·æ›´æ–°åŒ¹é…æ¥æº\n",
        "intake_df[\"Match_source\"] = intake_df.apply(lambda row: (\n",
        "    \"SBERT\" if pd.notna(row[\"NOVA_step4\"]) and pd.isna(row[\"NOVA_step1\"]) and pd.isna(row[\"NOVA_step2\"])\n",
        "    else row[\"Match_source\"]\n",
        "), axis=1)\n"
      ],
      "metadata": {
        "id": "NT3oNuGY8EUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å°† NOVA_final ç§»åŠ¨åˆ°æœ€åä¸€åˆ—\n",
        "col_order = [col for col in intake_df.columns if col != \"NOVA_final\"] + [\"NOVA_final\"]\n",
        "intake_df = intake_df[col_order]\n",
        "\n",
        "# ä¿å­˜ä¸º CSV\n",
        "intake_df.to_csv(\"/content/drive/MyDrive/UPF-HFI/outcome/intake_with_nova_step4_final.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "FSTQSiDGzFlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unmatched_final = intake_df[intake_df[\"NOVA_final\"].isin([None, \"\", \"NC\"])]\n",
        "print(f\"âŒ å®é™…æœªåŒ¹é…ä¸Šçš„é£Ÿç‰©æ•°é‡ï¼ˆå« NCï¼‰ï¼š{len(unmatched_final)}\")\n"
      ],
      "metadata": {
        "id": "WglYB0ua0dbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# æå–æœªåŒ¹é…çš„è¡Œï¼ˆNone, \"\", \"NC\"ï¼‰\n",
        "unmatched_final = intake_df[intake_df[\"NOVA_final\"].isin([None, \"\", \"NC\"])]\n",
        "\n",
        "# æŒ‰ food_name_clean ç»Ÿè®¡é¢‘ç‡\n",
        "nc_counts = unmatched_final[\"food_name_clean\"].value_counts().reset_index()\n",
        "nc_counts.columns = [\"food_name_clean\", \"count\"]\n",
        "\n",
        "# å±•ç¤ºå‰ 30 ä¸ªé«˜é¢‘æœªåŒ¹é…æ¡ç›®\n",
        "print(\"ğŸ½ï¸ é«˜é¢‘æœªåŒ¹é…é£Ÿç‰©ï¼ˆå‰30ï¼‰ï¼š\")\n",
        "print(nc_counts.head(30))\n",
        "\n",
        "# å¯é€‰ï¼šå¯¼å‡ºæˆ CSV æ–‡ä»¶\n",
        "nc_counts.to_csv(\"/content/high_freq_nc_foods.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "JxzlQm4K4qde"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}