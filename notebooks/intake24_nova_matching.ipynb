{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/DkhmJGBxLCTHWNCLkyFu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NINGTANG1124/UPF-HFI/blob/main/notebooks/intake24_nova_matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connect googledrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v9izKK0g9LUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: 读取 intake 数据（含 Descriptionen 和 FoodGroupen）\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/UPF-HFI/Bradford_original data/1. Dietmasterfile_foodlevel_clean.xls\"\n",
        "intake_df = pd.read_excel(file_path)\n"
      ],
      "metadata": {
        "id": "c7bYEbA49bs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: 清洗 Descriptionen 列\n",
        "def clean_description(desc):\n",
        "    if pd.isna(desc):\n",
        "        return \"\"\n",
        "    desc = str(desc).lower()\n",
        "    desc = re.sub(r\"[()\\.,\\-]\", \"\", desc)\n",
        "    desc = re.sub(r\"\\s+\", \" \", desc)\n",
        "    return desc.strip()\n",
        "\n",
        "intake_df[\"food_name_clean\"] = intake_df[\"Descriptionen\"].apply(clean_description)\n",
        "intake_df[\"Foodgroupen\"] = intake_df[\"Foodgroupen\"].fillna(\"\")\n"
      ],
      "metadata": {
        "id": "QbNxG8Re9glK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: 定义描述字段的规则匹配函数（宏观→微观）\n",
        "def match_nova_by_description_v3(text):\n",
        "    text = str(text).lower()\n",
        "\n",
        "    # === NOVA 1: 宏观 raw / water ===\n",
        "    if \"raw\" in text:\n",
        "        return 1, \"raw\"\n",
        "    if any(word in text for word in [\"tap water\", \"still water\", \"filtered water\"]):\n",
        "        return 1, \"water\"\n",
        "\n",
        "    # === NOVA 3: 宏观 homemade / boiled ===\n",
        "    if \"homemade\" in text or \"home made\" in text:\n",
        "        return 3, \"homemade item\"\n",
        "    if \"boiled\" in text or \"mashed potato\" in text:\n",
        "        return 3, \"boiled or mashed\"\n",
        "    if \"porridge made with milk\" in text:\n",
        "        return 3, \"porridge w/ milk\"\n",
        "\n",
        "    # === NOVA 4: 宏观加工类 ===\n",
        "    if \"takeaway\" in text:\n",
        "        return 4, \"fast food\"\n",
        "    if any(word in text for word in [\"ice cream topping\", \"breakfast cereal\", \"milkshake\"]):\n",
        "        return 4, \"dessert/snack item\"\n",
        "    if any(word in text for word in [\"flavour\", \"instant\"]):\n",
        "        return 4, \"instant/flavoured\"\n",
        "    if any(word in text for word in [\"cracker\", \"biscuit\", \"weetabix\"]):\n",
        "        return 4, \"snack item\"\n",
        "    if \"ketchup\" in text and \"home made\" not in text:\n",
        "        return 4, \"processed ketchup\"\n",
        "    if any(word in text for word in [\"squash\", \"cordial\", \"carbonated\"]):\n",
        "        return 4, \"sweetened drink\"\n",
        "    if any(word in text for word in [\"margarine\", \"clover spread\", \"flora\"]):\n",
        "        return 4, \"processed fat\"\n",
        "    if \"nutella\" in text:\n",
        "        return 4, \"branded sweet spread\"\n",
        "\n",
        "    # === NOVA 1: 微观乳制品类 ===\n",
        "    if any(word in text for word in [\"natural yoghurt\", \"whole milk\", \"fromage frais\"]) and \"flavour\" not in text:\n",
        "        return 1, \"plain dairy\"\n",
        "\n",
        "    return None, None\n"
      ],
      "metadata": {
        "id": "U_Q2G3Ez93zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: 定义 group 字段的匹配函数（宏观→微观）\n",
        "def match_nova_by_group_v2(group):\n",
        "    group = str(group).lower().strip()\n",
        "\n",
        "    # === NOVA 1 ===\n",
        "    if \"fresh fruit\" in group:\n",
        "        return 1, \"fruit (group)\"\n",
        "    if \"dried fruit\" in group:\n",
        "        return 1, \"dried fruit (group)\"\n",
        "    if \"vegetables\" in group and \"fried\" not in group:\n",
        "        return 1, \"vegetables (group)\"\n",
        "\n",
        "    # === NOVA 3 ===\n",
        "    if \"monounsaturated\" in group:\n",
        "        return 3, \"culinary fat (mono)\"\n",
        "    if \"dairy fat spreads\" in group or \"hard marg\" in group:\n",
        "        return 3, \"dairy fat spread\"\n",
        "\n",
        "    # === NOVA 4 ===\n",
        "    if \"other breakfast cereals\" in group or \"muesli\" in group or \"bran flakes\" in group:\n",
        "        return 4, \"processed cereal (group)\"\n",
        "    if \"ice cream\" in group or \"desserts and lollies\" in group:\n",
        "        return 4, \"ice cream (group)\"\n",
        "    if any(word in group for word in [\"sweets\", \"toffee\", \"boiled sweets\", \"gums\", \"jellies\", \"mints\", \"liquorice\", \"raw jelly\", \"popcorn\"]):\n",
        "        return 4, \"sweets/snack (group)\"\n",
        "\n",
        "    return None, None"
      ],
      "metadata": {
        "id": "7apLqZ-_-ECr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: 应用匹配逻辑（优先 description，再补 group）\n",
        "intake_df[[\"NOVA_by_desc\", \"Match_reason\"]] = intake_df[\"Descriptionen\"].apply(\n",
        "    lambda x: pd.Series(match_nova_by_description_v3(x))\n",
        ")\n",
        "\n",
        "mask_unmatched = intake_df[\"NOVA_by_desc\"].isna()\n",
        "intake_df.loc[mask_unmatched, [\"NOVA_by_desc\", \"Match_reason\"]] = intake_df.loc[mask_unmatched, \"Foodgroupen\"].apply(\n",
        "    lambda x: pd.Series(match_nova_by_group_v2(x))\n",
        ")\n",
        "\n",
        "# Step 6: 展示匹配样本结果\n",
        "matched_sample = intake_df[[\"food_name_clean\", \"Foodgroupen\", \"NOVA_by_desc\", \"Match_reason\"]].query(\"NOVA_by_desc.notna()\").head(20)\n",
        "matched_sample"
      ],
      "metadata": {
        "id": "_L-ZR4W9-LxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intake_df[\"NOVA_step1\"] = intake_df[\"NOVA_by_desc\"]\n"
      ],
      "metadata": {
        "id": "nzZB2lkh3_es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_save = [\n",
        "    \"food_name_clean\", \"Descriptionen\", \"Foodgroupen\",\n",
        "    \"NOVA_step1\", \"Match_reason\"\n",
        "]\n",
        "\n",
        "intake_df[cols_to_save].to_excel(\"/content/drive/MyDrive/UPF-HFI/outcome/intake_with_nova_step1.xlsx\", index=False)\n"
      ],
      "metadata": {
        "id": "Q9bpa0kH4CNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intake_df[cols_to_save].to_csv(\"/content/drive/MyDrive/UPF-HFI/outcome/intake_with_nova_step1.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "zNpLXy-_4YZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 Step 2: TF-IDF 高阈值匹配（>0.99）【数据源：VKesaite】 Intake 描述 vs FoodName 字段 特点：英国 NDNS 数据，语义贴合度高 匹配后字段： Matched_NOVA Source = 'tfidf_vk_099' Similarity_score\n",
        "\n",
        "🔹 Step 3: TF-IDF 中阈值匹配（>0.85）【数据源：Giulia FNDDS】 Intake 描述 vs FoodName/Description 字段（视结构而定） 特点：匹配面广但风格偏美式 可作为第二权重匹配源补充空值 匹配后： Source = 'tfidf_giulia_085'\n",
        "\n",
        "🔹 Step 4: TF-IDF 或 SBERT 语义匹配（>0.85）【数据源：OFF】 两种方式都可用： TF-IDF 匹配 product_name 字段 SBERT 匹配描述（推荐 MiniLM ） 用于最后补充空值，提高 recall（召回率） 匹配后： Source = 'tfidf_off' 或 'sbert_off'\n",
        "\n",
        "🔹 Step 5: 整合 + 人工补全 + Final 输出"
      ],
      "metadata": {
        "id": "2TluyxWVNvxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nova文件数据清洗\n",
        "# ndns\n",
        "ndns_df = pd.read_csv(\"/content/drive/MyDrive/UPF-HFI/nova/NDNS_NOVA_DATABASE.new2023.csv\", encoding=\"ISO-8859-1\")\n",
        "ndns_df.columns = ndns_df.columns.str.strip()\n",
        "ndns_df = ndns_df[[\"FoodName\", \"NOVA\"]].dropna()\n",
        "ndns_df[\"FoodName_clean\"] = ndns_df[\"FoodName\"].str.lower().str.replace(r\"[^\\w\\s]\", \" \", regex=True).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
        "ndns_df = ndns_df.drop_duplicates(subset=[\"FoodName_clean\"])\n"
      ],
      "metadata": {
        "id": "OMkARVTN1cMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "giulia_df = pd.read_excel(\"/content/drive/MyDrive/UPF-HFI/nova/Training Data Original Given by NOVA Researchers - Corrections by Giulia Babak FNDDS 2009-10.xls\")\n",
        "giulia_df.columns = giulia_df.columns.str.strip()\n",
        "print(giulia_df.columns.tolist())  # 找出正确列名\n"
      ],
      "metadata": {
        "id": "eJyrI0Mx2Zvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 美国的\n",
        "giulia_df = pd.read_excel(\"/content/drive/MyDrive/UPF-HFI/nova/Training Data Original Given by NOVA Researchers - Corrections by Giulia Babak FNDDS 2009-10.xls\")\n",
        "giulia_df.columns = giulia_df.columns.str.strip()\n",
        "\n",
        "giulia_df = giulia_df[[\"Main_food_description\", \"SR_nova_group\"]].dropna()\n",
        "giulia_df = giulia_df.rename(columns={\"Main_food_description\": \"FoodName\", \"SR_nova_group\": \"NOVA\"})\n",
        "\n",
        "giulia_df[\"FoodName_clean\"] = giulia_df[\"FoodName\"].str.lower().str.replace(r\"[^\\w\\s]\", \" \", regex=True).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
        "giulia_df = giulia_df.drop_duplicates(subset=[\"FoodName_clean\"])\n"
      ],
      "metadata": {
        "id": "AgvkK3io1vib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# off的\n",
        "off_clean = []\n",
        "with open(\"/content/drive/MyDrive/UPF-HFI/nova/openfoodfacts-popular-24.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            entry = json.loads(line)\n",
        "            if not isinstance(entry, dict):\n",
        "                continue  # 跳过非对象\n",
        "            name = entry.get(\"product_name\") or entry.get(\"abbreviated_product_name\")\n",
        "            nova = entry.get(\"nova_group\")\n",
        "            if name and nova:\n",
        "                name_clean = re.sub(r\"[^\\w\\s]\", \" \", name.lower())\n",
        "                name_clean = re.sub(r\"\\s+\", \" \", name_clean).strip()\n",
        "                off_clean.append({\"FoodName_clean\": name_clean, \"NOVA\": nova})\n",
        "        except json.JSONDecodeError:\n",
        "            continue  # 忽略错误行\n",
        "\n",
        "off_df = pd.DataFrame(off_clean).drop_duplicates(subset=[\"FoodName_clean\"])\n"
      ],
      "metadata": {
        "id": "rjtOfuR12Idz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ndns_df.to_csv(\"NDNS_clean.csv\", index=False)\n",
        "giulia_df.to_csv(\"Giulia_clean.csv\", index=False)\n",
        "off_df.to_csv(\"OFF_clean.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "4xz6rJST2_lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 2：TF-IDF 匹配未完成部分（基于 NOVA 对照池）\n",
        "\n",
        "# 🧱 1. 合并对照库作为 TF-IDF 的 reference\n",
        "nova_pool = pd.concat([ndns_df, giulia_df, off_df], ignore_index=True)\n",
        "nova_pool = nova_pool.drop_duplicates(subset=[\"FoodName_clean\"])\n",
        "\n",
        "# 🧱 2. 加载 intake 原始数据（含 Step1 结果）\n",
        "intake_df = pd.read_csv(\"/content/drive/MyDrive/UPF-HFI/outcome/intake_with_nova_step1.csv\")\n",
        "\n",
        "# 🧱 3. 选出 NOVA_step1 是缺失的食物\n",
        "mask_missing = intake_df[\"NOVA_step1\"].isna()\n",
        "query_texts = intake_df.loc[mask_missing, \"food_name_clean\"].dropna()\n",
        "query_texts_index = query_texts.index\n",
        "\n",
        "# 🧱 4. 构建 TF-IDF 向量器并转换\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_ref = vectorizer.fit_transform(nova_pool[\"FoodName_clean\"])\n",
        "tfidf_query = vectorizer.transform(query_texts)\n",
        "\n",
        "# 🧱 5. 匹配并返回得分和匹配内容\n",
        "similarity_matrix = cosine_similarity(tfidf_query, tfidf_ref)\n",
        "best_match_idx = similarity_matrix.argmax(axis=1)\n",
        "best_match_score = similarity_matrix.max(axis=1)\n",
        "matched_nova = nova_pool.iloc[best_match_idx][\"NOVA\"].values\n",
        "matched_name = nova_pool.iloc[best_match_idx][\"FoodName_clean\"].values\n",
        "\n",
        "# 🧱 6. 回写 intake_df 中\n",
        "intake_df.loc[query_texts_index, \"NOVA_step2\"] = matched_nova\n",
        "intake_df.loc[query_texts_index, \"TFIDF_score\"] = best_match_score\n",
        "intake_df.loc[query_texts_index, \"TFIDF_match_name\"] = matched_name\n",
        "\n",
        "# ✅ 可选：设置匹配阈值\n",
        "threshold = 0.85\n",
        "intake_df.loc[intake_df[\"TFIDF_score\"] < threshold, [\"NOVA_step2\", \"TFIDF_match_name\"]] = [None, None]\n",
        "\n",
        "# ✅ 保存输出\n",
        "intake_df.to_csv(\"/content/drive/MyDrive/UPF-HFI/outcome/intake_with_nova_step2.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "X-NxAZia6Jl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 2 分析代码\n",
        "# ✅ 1. 匹配成功数量和比例\n",
        "matched_tfidf = intake_df[\"NOVA_step2\"].notna().sum()\n",
        "total_tfidf_targets = intake_df[\"NOVA_step1\"].isna().sum()\n",
        "match_rate_tfidf = matched_tfidf / total_tfidf_targets\n",
        "\n",
        "print(f\"🔍 Step 2（TF-IDF）匹配成功数: {matched_tfidf} / {total_tfidf_targets} = {match_rate_tfidf:.2%}\")\n",
        "\n",
        "# ✅ 2. 匹配置信度统计\n",
        "print(\"\\n📊 TF-IDF 匹配得分描述性统计：\")\n",
        "print(intake_df[\"TFIDF_score\"].describe())\n",
        "\n",
        "# ✅ 3. 查看低置信度（得分 < 0.85）示例\n",
        "low_confidence = intake_df.query(\"TFIDF_score < 0.85 and TFIDF_score.notna()\").sort_values(by=\"TFIDF_score\")\n",
        "low_confidence[[\"food_name_clean\", \"TFIDF_match_name\", \"TFIDF_score\", \"NOVA_step2\"]].head(10)\n"
      ],
      "metadata": {
        "id": "IFYnCDwA61cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🧩 Step 3：合并 Step1 与 Step2 匹配结果，形成最终 NOVA 列\n",
        "\n",
        "def combine_nova(row):\n",
        "    if pd.notna(row[\"NOVA_step1\"]):\n",
        "        return row[\"NOVA_step1\"]\n",
        "    elif pd.notna(row[\"NOVA_step2\"]):\n",
        "        return row[\"NOVA_step2\"]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "intake_df[\"NOVA_final\"] = intake_df.apply(combine_nova, axis=1)\n",
        "\n",
        "# 同时保留来源（说明匹配来源是 Step1 / Step2 / None）\n",
        "def get_reason(row):\n",
        "    if pd.notna(row[\"NOVA_step1\"]):\n",
        "        return \"Keyword\"\n",
        "    elif pd.notna(row[\"NOVA_step2\"]):\n",
        "        return \"TF-IDF\"\n",
        "    else:\n",
        "        return \"Unmatched\"\n",
        "\n",
        "intake_df[\"Match_source\"] = intake_df.apply(get_reason, axis=1)\n",
        "\n",
        "# ✅ 保存最终结果\n",
        "intake_df.to_csv(\"/content/drive/MyDrive/UPF-HFI/outcome/intake_with_nova_step3.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "NX-zuEsc6jRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 3 分析代码：\n",
        "# ✅ 1. 匹配来源分布\n",
        "print(\"\\n📊 匹配来源分布统计：\")\n",
        "print(intake_df[\"Match_source\"].value_counts(dropna=False))\n",
        "print(\"\\n📊 匹配来源百分比：\")\n",
        "print(intake_df[\"Match_source\"].value_counts(normalize=True, dropna=False).map(\"{:.2%}\".format))\n",
        "\n",
        "# ✅ 2. 可选：每种 Match_source 在 Foodgroupen 中的分布（如需深入分析）\n",
        "# pd.crosstab(intake_df[\"Foodgroupen\"], intake_df[\"Match_source\"])\n"
      ],
      "metadata": {
        "id": "ieBV0-RY6-Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🎯 Step 4：使用 SBERT 对剩余 NOVA_final 为空的食物进行语义匹配补全"
      ],
      "metadata": {
        "id": "bcR92-jE7KdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "PqbMD6e87JlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 加载预训练模型（推荐 all-MiniLM-L6-v2）：\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
      ],
      "metadata": {
        "id": "x-po5i9d7vel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🛠 Step 4：对 NOVA_final 为空的食物进行 SBERT 匹配\n",
        "# ✅ 1. 准备候选库（对 nova_pool 编码）\n",
        "# 确保你之前准备好的 nova_pool 有 FoodName_clean 列\n",
        "ref_texts = nova_pool[\"FoodName_clean\"].tolist()\n",
        "ref_embeddings = model.encode(ref_texts, convert_to_tensor=True)\n"
      ],
      "metadata": {
        "id": "LCxkp7aG71gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 2. 选取待匹配食物（NOVA_final 为空）\n",
        "unmatched_df = intake_df[intake_df[\"NOVA_final\"].isna()].copy()\n",
        "query_texts = unmatched_df[\"food_name_clean\"].dropna().tolist()\n",
        "query_indices = unmatched_df[\"food_name_clean\"].dropna().index\n",
        "\n",
        "query_embeddings = model.encode(query_texts, convert_to_tensor=True)\n"
      ],
      "metadata": {
        "id": "lrebQJ1R75Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 3. 计算语义相似度并提取匹配结果\n",
        "cosine_scores = util.pytorch_cos_sim(query_embeddings, ref_embeddings)\n",
        "top_scores, top_indices = torch.max(cosine_scores, dim=1)\n",
        "\n",
        "# 写入结果\n",
        "intake_df.loc[query_indices, \"SBERT_score\"] = top_scores.cpu().numpy()\n",
        "intake_df.loc[query_indices, \"SBERT_match_name\"] = nova_pool.iloc[top_indices.cpu().numpy()][\"FoodName_clean\"].values\n",
        "intake_df.loc[query_indices, \"NOVA_step4\"] = nova_pool.iloc[top_indices.cpu().numpy()][\"NOVA\"].values\n"
      ],
      "metadata": {
        "id": "C6GsX7UD79Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 4. 更新最终列：NOVA_final + Match_source\n",
        "# 如果 Step3 没找到但 Step4 找到了，使用 SBERT 匹配结果\n",
        "intake_df[\"NOVA_final\"] = intake_df[\"NOVA_final\"].combine_first(intake_df[\"NOVA_step4\"])\n",
        "\n",
        "# 同样更新匹配来源\n",
        "intake_df[\"Match_source\"] = intake_df.apply(lambda row: (\n",
        "    \"SBERT\" if pd.notna(row[\"NOVA_step4\"]) and pd.isna(row[\"NOVA_step1\"]) and pd.isna(row[\"NOVA_step2\"])\n",
        "    else row[\"Match_source\"]\n",
        "), axis=1)\n"
      ],
      "metadata": {
        "id": "NT3oNuGY8EUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 将 NOVA_final 移动到最后一列\n",
        "col_order = [col for col in intake_df.columns if col != \"NOVA_final\"] + [\"NOVA_final\"]\n",
        "intake_df = intake_df[col_order]\n",
        "\n",
        "# 保存为 CSV\n",
        "intake_df.to_csv(\"/content/drive/MyDrive/UPF-HFI/outcome/intake_with_nova_step4_final.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "FSTQSiDGzFlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unmatched_final = intake_df[intake_df[\"NOVA_final\"].isin([None, \"\", \"NC\"])]\n",
        "print(f\"❌ 实际未匹配上的食物数量（含 NC）：{len(unmatched_final)}\")\n"
      ],
      "metadata": {
        "id": "WglYB0ua0dbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 提取未匹配的行（None, \"\", \"NC\"）\n",
        "unmatched_final = intake_df[intake_df[\"NOVA_final\"].isin([None, \"\", \"NC\"])]\n",
        "\n",
        "# 按 food_name_clean 统计频率\n",
        "nc_counts = unmatched_final[\"food_name_clean\"].value_counts().reset_index()\n",
        "nc_counts.columns = [\"food_name_clean\", \"count\"]\n",
        "\n",
        "# 展示前 30 个高频未匹配条目\n",
        "print(\"🍽️ 高频未匹配食物（前30）：\")\n",
        "print(nc_counts.head(30))\n",
        "\n",
        "# 可选：导出成 CSV 文件\n",
        "nc_counts.to_csv(\"/content/high_freq_nc_foods.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "JxzlQm4K4qde"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}