{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhssjPH+N7unl7sXzSIdjE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NINGTANG1124/UPF-HFI/blob/main/notebooks/step1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1yqVjTcQ-SQ",
        "outputId": "861c4b94-ac80-4d87-b2b6-3e310f03e8c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# connect googledrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read intake data (including Descriptionen and FoodGroupen)\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/UPF-HFI/Bradford_original data/1. Dietmasterfile_foodlevel_clean.xls\"\n",
        "intake_df = pd.read_excel(file_path)\n",
        "\n",
        "# Define text cleaning function\n",
        "def clean_text(col):\n",
        "    return col.astype(str).str.lower().str.strip().str.replace(r\"\\s+\", \" \", regex=True)\n",
        "\n",
        "# Apply to key fields\n",
        "intake_df[\"Foodgroupen_clean\"] = clean_text(intake_df[\"Foodgroupen\"])\n",
        "intake_df[\"Descriptionen_clean\"] = clean_text(intake_df[\"Descriptionen\"])\n",
        "\n",
        "# 添加 Subgroupcode 的清洗列\n",
        "intake_df[\"Subgroupcode_clean\"] = clean_text(intake_df[\"Subgroupcode\"])\n"
      ],
      "metadata": {
        "id": "b6POJBeQRI7s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置 att3 文件路径\n",
        "att3_path = \"/content/drive/MyDrive/UPF-HFI/nova matching files/att3-excel.xlsx\"\n",
        "\n",
        "# 读取 att3 文件\n",
        "att3 = pd.read_excel(att3_path)\n",
        "\n",
        "# 清洗 group code（假设列名为 'Subsidiary food group code'）\n",
        "att3['code_clean'] = att3['Subsidiary food group code'].astype(str).str.upper().str.strip()\n",
        "\n",
        "# 创建字典（包括 *）\n",
        "group_to_nova = dict(zip(att3['code_clean'], att3['NOVA food group']))\n",
        "\n",
        "# 清洗 intake 数据的 Subgroupcode 列\n",
        "intake_df['Subgroupcode_clean'] = intake_df['Subgroupcode'].astype(str).str.upper().str.strip()\n"
      ],
      "metadata": {
        "id": "i1G29oXXRti6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: 映射 group code 到 NOVA_step1\n",
        "intake_df['NOVA_step1'] = intake_df['Subgroupcode_clean'].map(group_to_nova)\n",
        "\n",
        "# Step 2: 添加匹配说明列（仅记录成功匹配的）\n",
        "intake_df['match_reason_step1'] = intake_df['NOVA_step1'].apply(\n",
        "    lambda x: 'group code match' if str(x).isdigit() else None\n",
        ")\n",
        "\n",
        "# 哪些行已经匹配成功？多少还没有？\n",
        "# 匹配情况预览\n",
        "intake_df['NOVA_step1'].value_counts(dropna=False)\n"
      ],
      "metadata": {
        "id": "6VhxgQWGR_yG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 导出检查文件（只保留关键列）\n",
        "cols_to_export = [\n",
        "    'Descriptionen', 'Foodgroupen',\n",
        "    'Subgroupcode', 'Subgroupcode_clean',\n",
        "    'NOVA_step1', 'match_reason_step1'\n",
        "]\n",
        "\n",
        "check_df = intake_df[cols_to_export].copy()\n",
        "check_df.to_excel(\"/content/drive/MyDrive/UPF-HFI/0728outcome/step1.xlsx\", index=False)\n"
      ],
      "metadata": {
        "id": "lputL_FtUXeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 精准提取 Step 2 目标项（NOVA_step1 是 * 或 **）"
      ],
      "metadata": {
        "id": "kHIFUeRLVhvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2：提取目标记录（NOVA 是 * 或 **）\n",
        "df_step2_targets = intake_df[intake_df['NOVA_step1'].isin([\"*\", \"**\"])].copy()\n",
        "\n",
        "# 按 Subgroupcode_clean 去重，只保留每组一个代表行\n",
        "df_step2_unique = df_step2_targets.drop_duplicates(subset=\"Subgroupcode_clean\")\n",
        "\n",
        "# 选择导出的关键列\n",
        "cols_step2 = [\n",
        "    'Descriptionen', 'Foodgroupen',\n",
        "    'Subgroupcode', 'Subgroupcode_clean',\n",
        "    'NOVA_step1', 'match_reason_step1'\n",
        "]\n",
        "df_step2_unique_simple = df_step2_unique[cols_step2]\n",
        "\n",
        "# 导出为 Excel 文件\n",
        "df_step2_unique_simple.to_excel(\"/content/drive/MyDrive/UPF-HFI/0728outcome/step2_groupcodes_unique.xlsx\", index=False)\n"
      ],
      "metadata": {
        "id": "HhuXkM5dTp55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 提取NaN\n"
      ],
      "metadata": {
        "id": "6Ov0HuACs1cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 提取 NOVA_step1 为 NaN 的记录（不去重）\n",
        "df_step2_nan_all = intake_df[intake_df['NOVA_step1'].isna()].copy()\n",
        "\n",
        "# 选择导出的关键列\n",
        "cols_step2_nan = [\n",
        "    'Descriptionen', 'Foodgroupen',\n",
        "    'Subgroupcode', 'Subgroupcode_clean',\n",
        "    'NOVA_step1', 'match_reason_step1'\n",
        "]\n",
        "df_step2_nan_all_simple = df_step2_nan_all[cols_step2_nan]\n",
        "\n",
        "# 导出为 Excel 文件\n",
        "df_step2_nan_all_simple.to_excel(\n",
        "    \"/content/drive/MyDrive/UPF-HFI/0728outcome/step2_groupcodes_NaN_all.xlsx\",\n",
        "    index=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "QIHCm-jOs1GJ",
        "outputId": "3864f3e8-9508-4d08-e11e-cbb49afb616f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'intake_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-430068272.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 提取 NOVA_step1 为 NaN 的记录（不去重）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_step2_nan_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintake_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mintake_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NOVA_step1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 选择导出的关键列\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m cols_step2_nan = [\n",
            "\u001b[0;31mNameError\u001b[0m: name 'intake_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ypWSQenss0X0"
      }
    }
  ]
}