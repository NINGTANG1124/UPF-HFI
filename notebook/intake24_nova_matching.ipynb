{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJanuw+gQsn3hFimSTGc5d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NINGTANG1124/UPF-HFI/blob/main/notebook/intake24_nova_matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connect googledrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9izKK0g9LUQ",
        "outputId": "06f043b2-8055-4105-ccf4-0eb58339e768"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: è¯»å– intake æ•°æ®ï¼ˆå« Descriptionen å’Œ FoodGroupenï¼‰\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/UPF-HFI/Bradford_original data/1. Dietmasterfile_foodlevel_clean.xls\"\n",
        "intake_df = pd.read_excel(file_path)\n"
      ],
      "metadata": {
        "id": "c7bYEbA49bs9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step2 æ¸…æ´— Description å’Œ Foodgroup\n",
        "intake_df[\"Foodgroupen_clean\"] = (\n",
        "    intake_df[\"Foodgroupen\"].astype(str).str.lower().str.strip().str.replace(r\"\\s+\", \" \", regex=True)\n",
        ")\n",
        "\n",
        "intake_df[\"Descriptionen_clean\"] = (\n",
        "    intake_df[\"Descriptionen\"].astype(str).str.lower().str.strip().str.replace(r\"\\s+\", \" \", regex=True)\n",
        ")\n"
      ],
      "metadata": {
        "id": "QbNxG8Re9glK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# description\n",
        "def match_nova_by_description(text):\n",
        "    text = str(text).lower().strip()\n",
        "\n",
        "    # === NOVA 1: é¥®ç”¨æ°´ ===\n",
        "    if any(w in text for w in [\"tap water\", \"still water\", \"filtered water\", \"plain water\"]):\n",
        "        if \"flavour\" not in text:\n",
        "            return 1, \"plain water (description)\"\n",
        "\n",
        "    # === NOVA 1: å¾®è§‚ä¹³åˆ¶å“ï¼ˆplainï¼‰===\n",
        "    if any(w in text for w in [\"semi skimmed milk\", \"skimmed milk\", \"whole milk\"]) and \"flavour\" not in text:\n",
        "        return 1, \"plain milk\"\n",
        "    if any(w in text for w in [\"natural yoghurt\", \"fromage frais\"]) and \"flavour\" not in text:\n",
        "        return 1, \"plain yoghurt\"\n",
        "\n",
        "    # === NOVA 1: ç²¾ç¡® raw/unprocessed ===\n",
        "    import re\n",
        "\n",
        "    if re.search(r'\\braw\\b', text):\n",
        "        return 1, \"raw (word-bound)\"\n",
        "\n",
        "    # === NOVA 3: è‡ªåˆ¶ã€è½»åŠ å·¥ ===\n",
        "    if any(w in text for w in [\"homemade\", \"home made\"]):\n",
        "        return 3, \"homemade\"\n",
        "    if any(w in text for w in [\"boiled\", \"mashed potato\", \"baked potato\", \"jacket potato\"]):\n",
        "        return 3, \"boiled/baked/jacket\"\n",
        "\n",
        "    # === NOVA 4: å·¥ä¸šåŠ å·¥éº¦ç‰‡ï¼ˆå¦‚sachetç±»ï¼‰===\n",
        "    if \"porridge sachet\" in text or (\"porridge\" in text and \"oat so simple\" in text):\n",
        "        return 4, \"sachet porridge (description)\"\n",
        "\n",
        "    # === NOVA 4: takeaway å¿«é¤ç±» ===\n",
        "    if \"takeaway\" in text or \"take away\" in text:\n",
        "        return 4, \"takeaway food\"\n",
        "\n",
        "    # === NOVA 4: é›¶é£Ÿ/ç”œé£Ÿ/åŠ å·¥è„‚è‚ª ===\n",
        "    if any(w in text for w in [\"jam\", \"conserve\", \"marmalade\", \"chocolate spread\", \"ice cream topping\", \"marzipan\"]):\n",
        "        return 4, \"spread/syrup\"\n",
        "    if any(w in text for w in [\"cracker\", \"savoury biscuit\", \"cheddar biscuit\", \"cream cracker\"]):\n",
        "        return 4, \"processed snack\"\n",
        "    if any(w in text for w in [\"sweets\", \"gums\", \"jellies\", \"boiled sweets\", \"mints\", \"liquorice\", \"popcorn\"]):\n",
        "        return 4, \"sweet snack\"\n",
        "    if any(w in text for w in [\"ice cream\", \"dessert\", \"milkshake\"]):\n",
        "        return 4, \"processed dessert\"\n",
        "    if any(w in text for w in [\"margarine\", \"clover spread\", \"flora\"]):\n",
        "        return 4, \"processed fat\"\n",
        "    if \"flavoured milk\" in text or \"chocolate milk\" in text:\n",
        "        return 4, \"flavoured milk\"\n",
        "    if \"ketchup\" in text and \"home made\" not in text:\n",
        "        return 4, \"processed ketchup\"\n",
        "    if \"instant\" in text and \"porridge\" not in text:\n",
        "        return 4, \"instant food\"\n",
        "    # === NOVA 4: takeaway å¿«é¤ç±» ===\n",
        "    if \"takeaway\" in text or \"take away\" in text:\n",
        "        return 4, \"takeaway food\"\n",
        "\n",
        "    return None, None\n"
      ],
      "metadata": {
        "id": "qYXdm7e1rO18"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# group\n",
        "def match_nova_by_group(group, description):\n",
        "    group = str(group).lower().strip()\n",
        "    description = str(description).lower().strip()\n",
        "\n",
        "    # === NOVA 1: group ç²¾ç¡®åŒ¹é… water ç±» ===\n",
        "    if group.strip() in [\"water\", \"tap water\", \"filtered water\"]:\n",
        "        return 1, \"water (group)\"\n",
        "\n",
        "    # === NOVA 1: æœªåŠ å·¥æœè”¬ã€ç‰›å¥¶ã€é…¸å¥¶ ===\n",
        "    if \"fresh fruit\" in group:\n",
        "        return 1, \"fruit (group)\"\n",
        "    if \"dried fruit\" in group:\n",
        "        return 1, \"dried fruit (group)\"\n",
        "    if \"vegetables\" in group and \"fried\" not in group:\n",
        "        return 1, \"vegetables (group)\"\n",
        "    if any(word in group for word in [\"semi skimmed milk\", \"skimmed milk\", \"whole milk\"]):\n",
        "        if \"flavour\" not in description and \"fruit\" not in description:\n",
        "            return 1, \"milk (group)\"\n",
        "    if any(word in group for word in [\"natural yoghurt\", \"fromage frais\"]):\n",
        "        if \"flavour\" not in description and \"fruit\" not in description:\n",
        "            return 1, \"yoghurt/plain dairy (group)\"\n",
        "\n",
        "    # === NOVA 3: æœ€å°åŠ å·¥è„‚è‚ª ===\n",
        "    if any(w in group for w in [\"olive oil\", \"rapeseed oil\", \"sunflower oil\", \"vegetable oil\", \"butter\"]):\n",
        "        return 3, \"culinary fat/oil (group)\"\n",
        "\n",
        "    # === NOVA 4: ç³–æµ†ã€æ—©é¤è°·ç‰©ã€åŠ å·¥è„‚è‚ª ===\n",
        "    if any(w in group for w in [\"margarine\", \"fat spread\", \"flora\", \"dairy fat spreads\", \"hard marg\"]):\n",
        "        return 4, \"processed fat (group)\"\n",
        "    if any(w in group for w in [\"jam\", \"conserve\", \"marmalade\"]):\n",
        "        return 4, \"preserves (group)\"\n",
        "    if \"other breakfast cereals\" in group or \"muesli\" in group or \"bran flakes\" in group:\n",
        "        return 4, \"processed cereal (group)\"\n",
        "\n",
        "    return None, None\n"
      ],
      "metadata": {
        "id": "zRt397tRpuES"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(intake_df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Qbhgb3xD9Aq",
        "outputId": "80864d04-25c8-4c69-df78-bae20192f057"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['SurveyID', 'UserID', 'Source', 'Starttime', 'Submissiontime',\n",
            "       'Timetocomplete', 'Cookingoilused', 'Diet', 'Foodamount',\n",
            "       'Reasonforunusualfoodamount',\n",
            "       ...\n",
            "       'Modification_Identification', 'discontinued', 'NDNS_Checks',\n",
            "       'UserID_specific', 'Day', 'weekday', 'ratio', 'UserID_clean',\n",
            "       'Foodgroupen_clean', 'Descriptionen_clean'],\n",
            "      dtype='object', length=168)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CXyb9JwmQuYs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Step 3: å®šä¹‰ä¸»å‡½æ•° match_nova()\n",
        "def match_nova(row):\n",
        "    description = row[\"Descriptionen_clean\"]\n",
        "    group = row[\"Foodgroupen_clean\"]\n",
        "\n",
        "    # Step 1: try description\n",
        "    nova, reason = match_nova_by_description(description)\n",
        "    if nova is not None:\n",
        "        return pd.Series([nova, \"description: \" + reason])\n",
        "\n",
        "    # Step 2: fallback to group\n",
        "    nova, reason = match_nova_by_group(group, description)\n",
        "    if nova is not None:\n",
        "        return pd.Series([nova, \"group: \" + reason])\n",
        "\n",
        "    return pd.Series([None, None])\n"
      ],
      "metadata": {
        "id": "LgPplkugtTTV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intake_df[[\"NOVA_step1\", \"match_reason\"]] = intake_df.apply(match_nova, axis=1)"
      ],
      "metadata": {
        "id": "-FKu22i2tWJ9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_save = [\n",
        "    \"Descriptionen\",\n",
        "    \"Descriptionen_clean\",\n",
        "    \"Foodgroupen\",\n",
        "    \"Foodgroupen_clean\",\n",
        "    \"NOVA_step1\",      # æ”¹è¿™é‡Œ\n",
        "    \"match_reason\"\n",
        "]\n",
        "intake_df[cols_to_save].to_csv(\"/content/drive/MyDrive/UPF-HFI/outcome/intake_with_nova_step1.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "pkShExdwiNwg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ”¹ Step 2: TF-IDF é«˜é˜ˆå€¼åŒ¹é…ï¼ˆ>0.99ï¼‰ã€æ•°æ®æºï¼šVKesaiteã€‘ Intake æè¿° vs FoodName å­—æ®µ ç‰¹ç‚¹ï¼šè‹±å›½ NDNS æ•°æ®ï¼Œè¯­ä¹‰è´´åˆåº¦é«˜ åŒ¹é…åå­—æ®µï¼š Matched_NOVA Source = 'tfidf_vk_099' Similarity_score\n",
        "\n",
        "ğŸ”¹ Step 3: TF-IDF ä¸­é˜ˆå€¼åŒ¹é…ï¼ˆ>0.85ï¼‰ã€æ•°æ®æºï¼šGiulia FNDDSã€‘ Intake æè¿° vs FoodName/Description å­—æ®µï¼ˆè§†ç»“æ„è€Œå®šï¼‰ ç‰¹ç‚¹ï¼šåŒ¹é…é¢å¹¿ä½†é£æ ¼åç¾å¼ å¯ä½œä¸ºç¬¬äºŒæƒé‡åŒ¹é…æºè¡¥å……ç©ºå€¼ åŒ¹é…åï¼š Source = 'tfidf_giulia_085'\n",
        "\n",
        "ğŸ”¹ Step 4: TF-IDF æˆ– SBERT è¯­ä¹‰åŒ¹é…ï¼ˆ>0.85ï¼‰ã€æ•°æ®æºï¼šOFFã€‘ ä¸¤ç§æ–¹å¼éƒ½å¯ç”¨ï¼š TF-IDF åŒ¹é… product_name å­—æ®µ SBERT åŒ¹é…æè¿°ï¼ˆæ¨è MiniLM ï¼‰ ç”¨äºæœ€åè¡¥å……ç©ºå€¼ï¼Œæé«˜ recallï¼ˆå¬å›ç‡ï¼‰ åŒ¹é…åï¼š Source = 'tfidf_off' æˆ– 'sbert_off'\n",
        "\n",
        "ğŸ”¹ Step 5: æ•´åˆ + äººå·¥è¡¥å…¨ + Final è¾“å‡º"
      ],
      "metadata": {
        "id": "2TluyxWVNvxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# novaæ–‡ä»¶æ•°æ®æ¸…æ´—\n",
        "# ndns\n",
        "ndns_df = pd.read_csv(\"/content/drive/MyDrive/UPF-HFI/nova/NDNS_NOVA_DATABASE.new2023.csv\", encoding=\"ISO-8859-1\")\n",
        "ndns_df.columns = ndns_df.columns.str.strip()\n",
        "ndns_df = ndns_df[[\"FoodName\", \"NOVA\"]].dropna()\n",
        "ndns_df[\"FoodName_clean\"] = ndns_df[\"FoodName\"].str.lower().str.replace(r\"[^\\w\\s]\", \" \", regex=True).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
        "ndns_df = ndns_df.drop_duplicates(subset=[\"FoodName_clean\"])\n"
      ],
      "metadata": {
        "id": "OMkARVTN1cMN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ç¾å›½çš„\n",
        "giulia_df = pd.read_excel(\"/content/drive/MyDrive/UPF-HFI/nova/Training Data Original Given by NOVA Researchers - Corrections by Giulia Babak FNDDS 2009-10.xls\")\n",
        "giulia_df.columns = giulia_df.columns.str.strip()\n",
        "\n",
        "giulia_df = giulia_df[[\"Main_food_description\", \"SR_nova_group\"]].dropna()\n",
        "giulia_df = giulia_df.rename(columns={\"Main_food_description\": \"FoodName\", \"SR_nova_group\": \"NOVA\"})\n",
        "\n",
        "giulia_df[\"FoodName_clean\"] = giulia_df[\"FoodName\"].str.lower().str.replace(r\"[^\\w\\s]\", \" \", regex=True).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
        "giulia_df = giulia_df.drop_duplicates(subset=[\"FoodName_clean\"])\n"
      ],
      "metadata": {
        "id": "AgvkK3io1vib"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# offçš„\n",
        "off_clean = []\n",
        "with open(\"/content/drive/MyDrive/UPF-HFI/nova/openfoodfacts-popular-24.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            entry = json.loads(line)\n",
        "            if not isinstance(entry, dict):\n",
        "                continue  # è·³è¿‡éå¯¹è±¡\n",
        "            name = entry.get(\"product_name\") or entry.get(\"abbreviated_product_name\")\n",
        "            nova = entry.get(\"nova_group\")\n",
        "            if name and nova:\n",
        "                name_clean = re.sub(r\"[^\\w\\s]\", \" \", name.lower())\n",
        "                name_clean = re.sub(r\"\\s+\", \" \", name_clean).strip()\n",
        "                off_clean.append({\"FoodName_clean\": name_clean, \"NOVA\": nova})\n",
        "        except json.JSONDecodeError:\n",
        "            continue  # å¿½ç•¥é”™è¯¯è¡Œ\n",
        "\n",
        "off_df = pd.DataFrame(off_clean).drop_duplicates(subset=[\"FoodName_clean\"])\n"
      ],
      "metadata": {
        "id": "rjtOfuR12Idz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ndns_df.to_csv(\"NDNS_clean.csv\", index=False)\n",
        "giulia_df.to_csv(\"Giulia_clean.csv\", index=False)\n",
        "off_df.to_csv(\"OFF_clean.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "4xz6rJST2_lG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Step 2ï¼šTF-IDF åŒ¹é…æœªå®Œæˆéƒ¨åˆ†ï¼ˆåŸºäº NOVA å¯¹ç…§æ± ï¼‰\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "OTXojW7IbVIm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 1. æ„å»º TF-IDF åŒ¹é…å‚è€ƒåº“ï¼ˆNOVA poolï¼‰\n",
        "nova_pool = pd.concat([ndns_df, giulia_df, off_df], ignore_index=True)\n",
        "nova_pool = nova_pool.drop_duplicates(subset=[\"FoodName_clean\"])  # æ³¨æ„ï¼šæˆ‘ä»¬ç”¨ FoodName_clean ä½œä¸º reference\n",
        "\n",
        "# âœ… 2. åŠ è½½ intake æ•°æ®ï¼ˆåŒ…å« Step1 çš„ç»“æœï¼‰\n",
        "intake_df = pd.read_csv(\"/content/drive/MyDrive/UPF-HFI/outcome/intake_with_nova_step1.csv\")\n",
        "\n",
        "# âœ… 3. é€‰å‡º Step1 æœªåŒ¹é…çš„é¡¹ï¼ˆç¼ºå¤± NOVA_step1 çš„ï¼‰\n",
        "mask_missing = intake_df[\"NOVA_step1\"].isna()\n",
        "query_texts = intake_df.loc[mask_missing, \"Descriptionen_clean\"].dropna()\n",
        "query_texts_index = query_texts.index\n",
        "\n",
        "# âœ… 4. æ„å»º TF-IDF å‘é‡å™¨å¹¶è½¬æ¢ä¸ºå‘é‡\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_ref = vectorizer.fit_transform(nova_pool[\"FoodName_clean\"])  # å‚è€ƒåº“ï¼šFoodName_clean\n",
        "tfidf_query = vectorizer.transform(query_texts)                    # æŸ¥è¯¢é¡¹ï¼šDescriptionen_clean\n",
        "\n",
        "# âœ… 5. è®¡ç®—ç›¸ä¼¼åº¦å¾—åˆ†å’Œç´¢å¼•\n",
        "similarity_matrix = cosine_similarity(tfidf_query, tfidf_ref)\n",
        "best_match_idx = similarity_matrix.argmax(axis=1)\n",
        "best_match_score = similarity_matrix.max(axis=1)\n",
        "\n",
        "# âœ… 6. ä»åŒ¹é…ä½ç½®æå– nova åˆ†æ•°ä¸åŒ¹é…åç§°\n",
        "matched_nova = nova_pool.iloc[best_match_idx][\"NOVA\"].values\n",
        "matched_name = nova_pool.iloc[best_match_idx][\"FoodName_clean\"].values\n",
        "\n",
        "# âœ… 7. å›å†™è¿› intake æ•°æ®\n",
        "intake_df.loc[query_texts_index, \"NOVA_step2\"] = matched_nova\n",
        "intake_df.loc[query_texts_index, \"TFIDF_score\"] = best_match_score\n",
        "intake_df.loc[query_texts_index, \"TFIDF_match_name\"] = matched_name\n",
        "\n",
        "# âœ… 8. å¯é€‰ï¼šè¿‡æ»¤ä½äºé˜ˆå€¼çš„åŒ¹é…ç»“æœï¼ˆè®¾ç½®ä¸º Noneï¼‰\n",
        "threshold = 0.85\n",
        "intake_df.loc[intake_df[\"TFIDF_score\"] < threshold, [\"NOVA_step2\", \"TFIDF_match_name\"]] = [None, None]\n",
        "\n",
        "# âœ… 9. ä¿å­˜æœ€ç»ˆç»“æœ\n",
        "intake_df.to_csv(\"/content/drive/MyDrive/UPF-HFI/outcome/intake_with_nova_step2.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "X-NxAZia6Jl1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ§© Step 3ï¼šåˆå¹¶ Step1 ä¸ Step2 åŒ¹é…ç»“æœï¼Œå½¢æˆæœ€ç»ˆ NOVA åˆ—\n",
        "\n",
        "def combine_nova(row):\n",
        "    if pd.notna(row[\"NOVA_step1\"]):\n",
        "        return row[\"NOVA_step1\"]\n",
        "    elif pd.notna(row[\"NOVA_step2\"]):\n",
        "        return row[\"NOVA_step2\"]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "intake_df[\"NOVA_final\"] = intake_df.apply(combine_nova, axis=1)\n",
        "\n",
        "# åŒæ—¶ä¿ç•™æ¥æºï¼ˆè¯´æ˜åŒ¹é…æ¥æºæ˜¯ Step1 / Step2 / Noneï¼‰\n",
        "def get_reason(row):\n",
        "    if pd.notna(row[\"NOVA_step1\"]):\n",
        "        return \"Keyword\"\n",
        "    elif pd.notna(row[\"NOVA_step2\"]):\n",
        "        return \"TF-IDF\"\n",
        "    else:\n",
        "        return \"Unmatched\"\n",
        "\n",
        "intake_df[\"Match_source\"] = intake_df.apply(get_reason, axis=1)\n",
        "\n",
        "# âœ… ä¿å­˜æœ€ç»ˆç»“æœ\n",
        "intake_df.to_csv(\"/content/drive/MyDrive/UPF-HFI/outcome/intake_with_nova_step3.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "NX-zuEsc6jRB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ¯ Step 4ï¼šä½¿ç”¨ SBERT å¯¹å‰©ä½™ NOVA_final ä¸ºç©ºçš„é£Ÿç‰©è¿›è¡Œè¯­ä¹‰åŒ¹é…è¡¥å…¨"
      ],
      "metadata": {
        "id": "bcR92-jE7KdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "PqbMD6e87JlI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆæ¨è all-MiniLM-L6-v2ï¼‰ï¼š\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-po5i9d7vel",
        "outputId": "289408f2-c3a1-4907-e493-ffc1738df4f8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ›  Step 4ï¼šå¯¹ NOVA_final ä¸ºç©ºçš„é£Ÿç‰©è¿›è¡Œ SBERT åŒ¹é…\n",
        "# âœ… 1. å‡†å¤‡å€™é€‰åº“ï¼ˆå¯¹ nova_pool ç¼–ç ï¼‰\n",
        "# ç¡®ä¿ä½ ä¹‹å‰å‡†å¤‡å¥½çš„ nova_pool æœ‰ FoodName_clean åˆ—\n",
        "ref_texts = nova_pool[\"FoodName_clean\"].tolist()\n",
        "ref_embeddings = model.encode(ref_texts, convert_to_tensor=True)\n"
      ],
      "metadata": {
        "id": "LCxkp7aG71gB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 2. é€‰å–å¾…åŒ¹é…é£Ÿç‰©ï¼ˆNOVA_final ä¸ºç©ºï¼‰\n",
        "unmatched_df = intake_df[intake_df[\"NOVA_final\"].isna()].copy()\n",
        "query_texts = unmatched_df[\"Descriptionen_clean\"].dropna().tolist()\n",
        "query_indices = unmatched_df[\"Descriptionen_clean\"].dropna().index\n",
        "\n",
        "query_embeddings = model.encode(query_texts, convert_to_tensor=True)\n"
      ],
      "metadata": {
        "id": "lrebQJ1R75Y8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 3. è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦å¹¶æå–åŒ¹é…ç»“æœ\n",
        "cosine_scores = util.pytorch_cos_sim(query_embeddings, ref_embeddings)\n",
        "top_scores, top_indices = torch.max(cosine_scores, dim=1)\n",
        "\n",
        "# å†™å…¥ç»“æœ\n",
        "intake_df.loc[query_indices, \"SBERT_score\"] = top_scores.cpu().numpy()\n",
        "intake_df.loc[query_indices, \"SBERT_match_name\"] = nova_pool.iloc[top_indices.cpu().numpy()][\"FoodName_clean\"].values\n",
        "intake_df.loc[query_indices, \"NOVA_step4\"] = nova_pool.iloc[top_indices.cpu().numpy()][\"NOVA\"].values\n"
      ],
      "metadata": {
        "id": "C6GsX7UD79Cy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 4. æ›´æ–°æœ€ç»ˆåˆ—ï¼šNOVA_final + Match_source\n",
        "# å¦‚æœ Step3 æ²¡æ‰¾åˆ°ä½† Step4 æ‰¾åˆ°äº†ï¼Œä½¿ç”¨ SBERT åŒ¹é…ç»“æœ\n",
        "intake_df[\"NOVA_final\"] = intake_df[\"NOVA_final\"].combine_first(intake_df[\"NOVA_step4\"])\n",
        "\n",
        "# åŒæ ·æ›´æ–°åŒ¹é…æ¥æº\n",
        "intake_df[\"Match_source\"] = intake_df.apply(lambda row: (\n",
        "    \"SBERT\" if pd.notna(row[\"NOVA_step4\"]) and pd.isna(row[\"NOVA_step1\"]) and pd.isna(row[\"NOVA_step2\"])\n",
        "    else row[\"Match_source\"]\n",
        "), axis=1)\n"
      ],
      "metadata": {
        "id": "NT3oNuGY8EUt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(intake_df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilA1fLqHNZ6s",
        "outputId": "344874c1-d52a-4f3f-d1ef-96efbefcfea0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Descriptionen', 'Descriptionen_clean', 'Foodgroupen', 'Foodgroupen_clean', 'NOVA_step1', 'match_reason', 'NOVA_step2', 'TFIDF_score', 'TFIDF_match_name', 'NOVA_final', 'Match_source', 'SBERT_score', 'SBERT_match_name', 'NOVA_step4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_order = [\n",
        "    \"Descriptionen\", \"Descriptionen_clean\", \"Foodgroupen\", \"Foodgroupen_clean\",\n",
        "\n",
        "    # === Step 1: Keyword åŒ¹é… ===\n",
        "    \"NOVA_step1\", \"match_reason\",\n",
        "\n",
        "    # === Step 2: TF-IDF åŒ¹é… ===\n",
        "    \"NOVA_step2\", \"TFIDF_match_name\", \"TFIDF_score\",\n",
        "\n",
        "    # === Step 3: SBERT åŒ¹é… ===\n",
        "    \"NOVA_step4\", \"SBERT_match_name\", \"SBERT_score\",\n",
        "\n",
        "    # === æœ€ç»ˆç»“æœ ===\n",
        "    \"NOVA_final\", \"Match_source\"\n",
        "]\n",
        "\n",
        "\n",
        "# æŒ‰åˆ—é¡ºåºå¯¼å‡º\n",
        "intake_df = intake_df[col_order]\n",
        "intake_df.to_csv(\"/content/drive/MyDrive/UPF-HFI/outcome/intake_with_nova_step4_final.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "FSTQSiDGzFlx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unmatched_final = intake_df[intake_df[\"NOVA_final\"].isin([None, \"\", \"NC\"])]\n",
        "print(f\"æœªåŒ¹é…ä¸Šçš„é£Ÿç‰©æ•°é‡ï¼š{len(unmatched_final)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WglYB0ua0dbF",
        "outputId": "8766ad68-c708-4a78-8754-e6aa84492c50"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æœªåŒ¹é…ä¸Šçš„é£Ÿç‰©æ•°é‡ï¼š414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# æå–æœªåŒ¹é…çš„è¡Œï¼ˆNone, \"\", \"NC\"ï¼‰\n",
        "unmatched_final = intake_df[intake_df[\"NOVA_final\"].isin([None, \"\", \"NC\"])]\n",
        "\n",
        "# ç”¨ Descriptionen_clean ç»Ÿè®¡é¢‘ç‡\n",
        "nc_counts = unmatched_final[\"Descriptionen_clean\"].value_counts().reset_index()\n",
        "nc_counts.columns = [\"Descriptionen_clean\", \"count\"]\n",
        "\n",
        "\n",
        "# å±•ç¤ºå‰ 30 ä¸ªé«˜é¢‘æœªåŒ¹é…æ¡ç›®\n",
        "print(\"é«˜é¢‘æœªåŒ¹é…é£Ÿç‰©ï¼ˆå‰30ï¼‰ï¼š\")\n",
        "print(nc_counts.head(30))\n",
        "\n",
        "# å¯é€‰ï¼šå¯¼å‡ºæˆ CSV æ–‡ä»¶\n",
        "nc_counts.to_csv(\"/content/high_freq_nc_foods.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxzlQm4K4qde",
        "outputId": "859e664e-e750-4e5b-b6e0-abcf0f418141"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "é«˜é¢‘æœªåŒ¹é…é£Ÿç‰©ï¼ˆå‰30ï¼‰ï¼š\n",
            "                                  Descriptionen_clean  count\n",
            "0   childrens' chewable vitamins with vitamin a (2...    240\n",
            "1                      vitamin d 400iu (10ug), tablet     34\n",
            "2        childrens' multivitamin and minerals, tablet     21\n",
            "3   bassetts chewy early health vitamins with a (4...     21\n",
            "4                   multivitamin and minerals, tablet     17\n",
            "5   childrens' vitamin c (120mg) plus zinc (3mg), ...     12\n",
            "6   prescription iron supplement, 27.5mg (e.g. syt...     12\n",
            "7                     childrens' multivitamins, drops     12\n",
            "8                    vitamin d 1000 iu (25ug), tablet      7\n",
            "9   wellkid multivitamin (age 4-12) (e.g. vitabiot...      7\n",
            "10  childrens' chewable multivitamins (age 3 plus)...      5\n",
            "11       calcium (250mg) & magnesium (157mg), capsule      4\n",
            "12         calcium (500mg) & vitamin d (10ug), tablet      4\n",
            "13                         magnesium (100 mg), tablet      4\n",
            "14                          vitamin c (200mg), tablet      3\n",
            "15              multivitamin with iron (14mg), tablet      2\n",
            "16                                iron (14mg), tablet      2\n",
            "17  calcium (400-600mg) with vitamin d (2-5ug), ta...      2\n",
            "18                         vitamin c (1000mg), tablet      1\n",
            "19          iron (14mg) with vitamin c (60mg), tablet      1\n",
            "20    fish oil (1100mg) with omega 3 (700mg), capsule      1\n",
            "21                      cod liver oil (500mg),capsule      1\n",
            "22  multivitamins (no minerals) (e.g. tesco/asda/b...      1\n"
          ]
        }
      ]
    }
  ]
}